{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в искусственные нейронные сети\n",
    "# Урок 5. Рекуррентные нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практическое задание\n",
    "\n",
    "<ol>\n",
    "    <li>Попробуйте изменить параметры нейронной сети работающей с датасетом imdb так, чтобы улучшить ее точность. Приложите анализ.</li>\n",
    "    <li>Попробуйте изменить параметры нейронной сети генерирующий текст таким образом, чтобы добиться генерации как можно более осмысленного текста. Пришлите лучший получившейся у вас текст и опишите, что вы предприняли, чтобы его получить. Можно использовать текст другого прозведения.</li>\n",
    "    <li>* Попробуйте на numpy реализовать нейронную сеть архитектуры LSTM</li>\n",
    "    <li>* Предложите свои варианты решения проблемы исчезающего градиента в RNN</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нейронная сеть работающая с датасетом imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 2s 0us/step\n",
      "17473536/17464789 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/muffin/anaconda3/lib/python3.8/site-packages/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/home/muffin/anaconda3/lib/python3.8/site-packages/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 200)\n",
      "x_test shape: (25000, 200)\n",
      "Построение модели...\n",
      "Процесс обучения...\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 516s 917ms/step - loss: 0.4937 - accuracy: 0.7481 - val_loss: 0.3698 - val_accuracy: 0.8497\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 480s 961ms/step - loss: 0.2965 - accuracy: 0.8819 - val_loss: 0.3155 - val_accuracy: 0.8667\n",
      "500/500 [==============================] - 130s 260ms/step - loss: 0.3155 - accuracy: 0.8667\n",
      "Результат при тестировании: 0.31545522809028625\n",
      "Тестовая точность: 0.8666800260543823\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, LSTM, SimpleRNN\n",
    "from keras.datasets import imdb\n",
    "\n",
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "tf.random.set_seed(48)\n",
    "\n",
    "max_features = 5000\n",
    "\n",
    "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
    "maxlen = 200\n",
    "batch_size = 50 # увеличьте значение для ускорения обучения\n",
    "\n",
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')\n",
    "\n",
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0, recurrent_dropout=0))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=2, # увеличьте при необходимости\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нейронная сеть генерирующая текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# построчное чтение из примера с текстом \n",
    "#with open(\"alice_in_wonderland.txt\", 'rb') as _in:\n",
    "with open(\"SSSR_anekdot.txt\", 'rb') as _in:\n",
    "    lines = []\n",
    "    for line in _in:\n",
    "        line = line.strip().lower().decode(\"utf-8\", \"ignore\")\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        lines.append(line)\n",
    "text = \" \".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxx Партия-бублик, народу-дырка от бублика! Это и есть советская республика! -\\xa0 Что такое РСФСР? -\\xa0 Редкий случай феноменального сумасшествия России. –\\xa0Скажите, вы коммунист? –\\xa0Нет, я сочувствующий. Но помочь ничем не могу! Муж возвращается с работы: –\\xa0Маша, я в партию вступил! Жена ворчит: –\\xa0Вечно ты во что-нибудь вступаешь!.. -Что такое РКП/б/? -\\xa0 Россия кончит погромом. –АВКП/б/? -\\xa0 Все кончится погромом. -\\xa0 Ну, а \"б\" в скобках? -\\xa0 Большим погромом! Крестьянин приехал в город, заходит в магазин и спрашивает: –\\xa0Нет ли у вас вожжей ? Продавец, не расслышав, показывает тому портреты вождей. Крестьянин замахал руками: –\\xa0Да нет, мне нужны настоящие, крепкие! хх Коммунизм – это советская власть плюс электрификация. Отсюда следует: советская власть – это коммунизм минус электрификация. Или : электрификация – это коммунизм минус советская власть. Из репродуктора доносится: \" Великая Октябрьская революция навеки освободила народ от цепей капитализма\". Старушка – внуку: –\\xa0Точно , так и было !'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Удалим неинформативные строки\n",
    "text = text.replace(\" xxx\", \"\") \n",
    "text = text.replace(\" ххх\", \"\") \n",
    "text = text.replace(\"  хх\", \"\") \n",
    "text = text.replace(\"   х\", \"\") \n",
    "text = text.replace(\" XXX\", \"\") \n",
    "text = text.replace(\"  - \", \"\") \n",
    "text = text.replace(\"  – \", \"\") \n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Итерация #: 0\n",
      "Epoch 1/10\n",
      "227/227 [==============================] - 1028s 4s/step - loss: 3.2474\n",
      "Epoch 2/10\n",
      "227/227 [==============================] - 1034s 5s/step - loss: 2.3074\n",
      "Epoch 3/10\n",
      "227/227 [==============================] - 968s 4s/step - loss: 1.9819\n",
      "Epoch 4/10\n",
      "227/227 [==============================] - 990s 4s/step - loss: 1.7418\n",
      "Epoch 5/10\n",
      "227/227 [==============================] - 969s 4s/step - loss: 1.5854\n",
      "Epoch 6/10\n",
      "227/227 [==============================] - 969s 4s/step - loss: 1.4505\n",
      "Epoch 7/10\n",
      "227/227 [==============================] - 1002s 4s/step - loss: 1.3267\n",
      "Epoch 8/10\n",
      "227/227 [==============================] - 968s 4s/step - loss: 1.2001\n",
      "Epoch 9/10\n",
      "227/227 [==============================] - 973s 4s/step - loss: 1.0711\n",
      "Epoch 10/10\n",
      "227/227 [==============================] - 992s 4s/step - loss: 0.9382\n",
      "Генерация из посева: ерь заклин\n",
      "ерь заклинило на право / что теперь бы мы им продавать ему два еврея, предлагает ему двух ударит социализм в помоще через два из села производства и хах маленького механического колхоза просят разрешить отпусти==================================================\n",
      "Итерация #: 1\n",
      "Epoch 1/10\n",
      "227/227 [==============================] - 969s 4s/step - loss: 0.8470\n",
      "Epoch 2/10\n",
      "227/227 [==============================] - 971s 4s/step - loss: 0.7224\n",
      "Epoch 3/10\n",
      "227/227 [==============================] - 992s 4s/step - loss: 0.6101\n",
      "Epoch 4/10\n",
      "227/227 [==============================] - 964s 4s/step - loss: 0.5116\n",
      "Epoch 5/10\n",
      "227/227 [==============================] - 966s 4s/step - loss: 0.4340\n",
      "Epoch 6/10\n",
      "227/227 [==============================] - 992s 4s/step - loss: 0.3731\n",
      "Epoch 7/10\n",
      "227/227 [==============================] - 965s 4s/step - loss: 0.3289\n",
      "Epoch 8/10\n",
      "227/227 [==============================] - 968s 4s/step - loss: 0.3002\n",
      "Epoch 9/10\n",
      "227/227 [==============================] - 990s 4s/step - loss: 0.2784\n",
      "Epoch 10/10\n",
      "227/227 [==============================] - 966s 4s/step - loss: 0.2667\n",
      "Генерация из посева: Товарищ Пе\n",
      "Товарищ Пельше, рад видеть вас!\" А он мне в ответ:\"А я не знаю.Спросим того еврея. Эй, товарищ , прямо скажите честно: смогли бы вы также хорошо – вот без мяса плохо! Покупатель спрашивает у студента: один горо==================================================\n",
      "Итерация #: 2\n",
      "Epoch 1/10\n",
      "227/227 [==============================] - 968s 4s/step - loss: 0.2535\n",
      "Epoch 2/10\n",
      "227/227 [==============================] - 1069s 5s/step - loss: 0.2481\n",
      "Epoch 3/10\n",
      "227/227 [==============================] - 1039s 5s/step - loss: 0.2436\n",
      "Epoch 4/10\n",
      "227/227 [==============================] - 1044s 5s/step - loss: 0.2399\n",
      "Epoch 5/10\n",
      "227/227 [==============================] - 1071s 5s/step - loss: 0.2374\n",
      "Epoch 6/10\n",
      "227/227 [==============================] - 1041s 5s/step - loss: 0.2344\n",
      "Epoch 7/10\n",
      "227/227 [==============================] - 1043s 5s/step - loss: 0.2316\n",
      "Epoch 8/10\n",
      "227/227 [==============================] - 1070s 5s/step - loss: 0.2279\n",
      "Epoch 9/10\n",
      "227/227 [==============================] - 1041s 5s/step - loss: 0.2282\n",
      "Epoch 10/10\n",
      "227/227 [==============================] - 1041s 5s/step - loss: 0.2277\n",
      "Генерация из посева: , так это \n",
      ", так это у Андропова : -  Ты как сюда попал ? -  По входному билету. -  А мне уже абореи. -  Дайте мне руководящих указание выпустить новые бумажные деньги все правители царили в России после октября 1917-го г\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "tf.random.set_seed(48)\n",
    "\n",
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)\n",
    "\n",
    "\n",
    "char2index = {c: i for i, c in enumerate(chars)}\n",
    "index2char = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "# для удобства выберете фиксированную длину последовательность 10 символов \n",
    "SEQLEN, STEP = 10, 1\n",
    "input_chars, label_chars = [], []\n",
    "\n",
    "# конвертация data в серии разных SEQLEN-length субпоследовательностей\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i: i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])\n",
    "\n",
    "\n",
    "# Вычисление one-hot encoding входных последовательностей X и следующего символа (the label) y\n",
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# установка ряда метапараметров  для нейронной сети и процесса тренировки\n",
    "BATCH_SIZE, HIDDEN_SIZE = 1128, 512 #128, 128\n",
    "NUM_ITERATIONS = 3 # 25 должно быть достаточно\n",
    "NUM_EPOCHS_PER_ITERATION = 10 #1\n",
    "NUM_PREDS_PER_EPOCH = 200 #100\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    GRU(  # вы можете изменить эту часть на LSTM или SimpleRNN, чтобы попробовать альтернативы\n",
    "        HIDDEN_SIZE,\n",
    "        return_sequences=True,\n",
    "        input_shape=(SEQLEN, nb_chars),\n",
    "        #dropout=0.2, \n",
    "        #unroll=True\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    GRU(  # вы можете изменить эту часть на LSTM или SimpleRNN, чтобы попробовать альтернативы\n",
    "        HIDDEN_SIZE,\n",
    "        return_sequences=True,\n",
    "        input_shape=(SEQLEN, nb_chars),\n",
    "        #dropout=0.2, \n",
    "        #unroll=True\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    GRU(  # вы можете изменить эту часть на LSTM или SimpleRNN, чтобы попробовать альтернативы\n",
    "        HIDDEN_SIZE,\n",
    "        return_sequences=False,\n",
    "        input_shape=(SEQLEN, nb_chars),\n",
    "        #dropout=0.2, \n",
    "        #unroll=True\n",
    "    )\n",
    ")\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\") #optimizer=\"rmsprop\")\n",
    "\n",
    "\n",
    "# выполнение серий тренировочных и демонстрационных итераций \n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "\n",
    "    # для каждой итерации запуск передачи данных в модель \n",
    "    print(\"=\" * 50)\n",
    "    print(\"Итерация #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "\n",
    "    # Select a random example input sequence.\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "\n",
    "    # для числа шагов предсказаний использование текущей тренируемой модели \n",
    "    # конструирование one-hot encoding для тестирования input и добавление предсказания.\n",
    "    print(\"Генерация из посева: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "\n",
    "        # здесь one-hot encoding.\n",
    "        X_test = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for j, ch in enumerate(test_chars):\n",
    "            X_test[0, j, char2index[ch]] = 1\n",
    "\n",
    "        # осуществление предсказания с помощью текущей модели.\n",
    "        pred = model.predict(X_test, verbose=0)[0]\n",
    "        y_pred = index2char[np.argmax(pred)]\n",
    "\n",
    "        # вывод предсказания добавленного к тестовому примеру \n",
    "        print(y_pred, end=\"\")\n",
    "\n",
    "        # инкрементация тестового примера содержащего предсказание\n",
    "        test_chars = test_chars[1:] + y_pred\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
